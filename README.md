# Are students learning the right skills for their future job?

This repository contains the entire workflow for our ODCM and DPREP group project (group 3). For our project we scraped indeed.com for several marketing analytics related job posts in the Netherlands. 



## Motivation
The job market is becoming ever more competitive, as a student nowadays it is harder and harder to land the job of your dreams. Covid has even made it more challenging for recent graduates to find a fitting role after graduation. A lot of students complain about the gap between skills learned during their studies and the actual skills required in the workfield by companies. This motivates our investigation into indeed job vacancy postings to find the skills that are actually required for different job types. As Marketing Analytics students, we have both the marketing and analytical knowledge to succeed in a range of different job types in the field of marketing. We are interested in what the actual required skills are for jobs in fields related to our studies. Becoming a data scientist, data analist or maybe marketeer after our studies will require different skills and competencies and we would like to know to which degree we possess the skills and to which extent our study program effectively prepares us for the job market. We aspire to find insights to help ourselves and our fellow students in making a choice which skills to improve and perhaps which skills to forego in order to effectively land their first job. We aim to conduct our investigation in such a way that the methodology can be used by anyone for any location in the world and for any job type.

## Method and results

First, introduce and motivate your chosen method, and explain how it contributes to solving the research question/business problem.

We find that for data-analist jobs, handling databases with SQL is the most sought after skill by employers. Followed by Microsoft Excel, Python and R. 

## Repository overview
Our repository is formed by the 

## Running instructions

For this project we made a makefile. This means that the whole proces from loading in the data to running the analyses can be done at once by running the makefile. If you are not (yet) familiar with makefiles, we advice you to take a look at the following tutorial before running the makefile: https://tilburgsciencehub.com/tutorials/reproducible-research/practicing-pipeline-automation-make/overview/ 
The makefile can be found in the ... folder. Please make sure to have a look at the makefile before you start running the file.

Before running the makefile make sure you have the following packages installed (copy paste the following one at a time in your terminal): 

| pip install requests |
pip install bs4 | 
pip install DateTime |
pip install selenium |
pip install pandas |


Explain to potential users how to run/replicate your workflow. Touch upon, if necessary, the required input data, which (secret) credentials are required (and how to obtain them), which software tools are needed to run the workflow (including links to the installation instructions), and how to run the workflow. Make use of subheaders where appropriate.

## More resources

Point interested users to any related literature and/or documentation.

## About

This project has been conducted by a student team from Tilburg University for the 2 courses Data Preparation & Management and Online Data Collection & Managemen, both instructed by Hannes Data. All team members were involved in building, developing, optimizing, cleaning, analyzing and reporting of the data. The following 4 students contributed to the project: Georgiana Huţanu, Anouk Heemskerk, Alan Rijnders and Renée Nieuwkoop. 

